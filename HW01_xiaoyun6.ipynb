{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 412 HW01\n",
    "Xiaoyun Zhuang\n",
    "2/24/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "`pd.describe()` is used to find the man, quartiles, mean and variances\\\n",
    "`pd.mode()` is used to find the mode.\n",
    "### 1.(a) Maximum and minimum\n",
    "Midterm socres: 37, 100\n",
    "Final scores: 35, 100\n",
    "\n",
    "### 1.(b) First quartile Q1, median, and third quartile Q3\n",
    "Midterm socres: 68, 77, 87\\\n",
    "Final scores: 82, 89, 96\n",
    "\n",
    "### 1.(c) Mean\n",
    "Midterm scores: 76.715\\\n",
    "Final scores: 87.084\n",
    "\n",
    "### 1.(d) Mode\n",
    "Midterm scores: 77, 83\\\n",
    "Final scores: 97\n",
    "\n",
    "### 1.(e) Variance\n",
    "Midterm scores: 173.279\\\n",
    "Final scores: 119.232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID     Midterm        Final\n",
      "count  1000.000000  1000.00000  1000.000000\n",
      "mean    499.500000    76.71500    87.084000\n",
      "std     288.819436    13.16355    10.919349\n",
      "min       0.000000    37.00000    35.000000\n",
      "25%     249.750000    68.00000    82.000000\n",
      "50%     499.500000    77.00000    89.000000\n",
      "75%     749.250000    87.00000    96.000000\n",
      "max     999.000000   100.00000   100.000000\n",
      "The mode of midterm is: 77 83\n",
      "The mode of final is: 97\n",
      "The variance of midterm is: 173.2790486025\n",
      "The variance of final is: 119.232182583801\n"
     ]
    }
   ],
   "source": [
    "scores = pd.read_csv(\"data.online.scores.txt\", delimiter=\"\\t\", names=[\"ID\",\"Midterm\",\"Final\"])\n",
    "print(scores.describe())\n",
    "print(\"The mode of midterm is: \" + ' '.join(map(str, scores.Midterm.mode()[0:].to_list())))\n",
    "print(\"The mode of final is: \" + ' '.join(map(str, scores.Final.mode()[0:].to_list())))\n",
    "print(\"The variance of midterm is: \" + str(13.16355**2))\n",
    "print(\"The variance of final is: \" + str(10.919349**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "- First, use `zscore` in `scipy` package to calculate the normalized scores.\n",
    "- Then, use the `.var()`, `.corr()`, and `.cov()` in `pandas` to calculate the variance, correlation coefficient and covariance.\n",
    "\n",
    "### 2.(a) Compute and compare the variance of midterm-original and midterm-normalized\n",
    "Midterm_original：173.279\\\n",
    "Midterm_normalized: 1.001\n",
    "\n",
    "### 2.(b) Given an original midterm score of 90, what is the corresponding score after normalization?\n",
    "1.009\n",
    "\n",
    "### 2.(c) Compute the Pearson’s correlation coefficient between midterm-original and finals-original.\n",
    "0.544425\n",
    "\n",
    "### 2.(d) Compute the Pearson’s correlation coefficient between midterm-normalized and finals-original.\n",
    "0.544425\n",
    "\n",
    "### 2.(e)  Compute the covariance between midterm-original and finals-original.\n",
    "78.2541941941942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the midterm scores are as below:\n",
      "midterm_original      173.279054\n",
      "midterm_normalized      1.001001\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "scores = pd.read_csv(\"data.online.scores.txt\", delimiter=\"\\t\", names=[\"ID\",\"Midterm\",\"Final\"])\n",
    "scores_z = scores.apply(zscore)\n",
    "data = [scores[\"Midterm\"], scores_z[\"Midterm\"]]\n",
    "headers = [\"midterm_original\", \"midterm_normalized\"]\n",
    "mid = pd.concat(data, axis=1, keys=headers)\n",
    "print(\"The variance of the midterm scores are as below:\")\n",
    "print(mid.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized score for 90 is: 1.009731210573523\n"
     ]
    }
   ],
   "source": [
    "norm_90 = mid.loc[mid[\"midterm_original\"]==90, \"midterm_normalized\"].iloc[1]\n",
    "print(\"The normalized score for 90 is: \" + str(norm_90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pearson’s correlation coefficient between midterm-original and finals-original is: 0.5444247423124133\n"
     ]
    }
   ],
   "source": [
    "cor1 = scores.corr(method=\"pearson\").iloc[1,2]\n",
    "print(\"The Pearson’s correlation coefficient between midterm-original and finals-original is: \"+str(cor1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pearson’s correlation coefficient between midterm-normalized and finals-original is: 0.544424742312412\n"
     ]
    }
   ],
   "source": [
    "cor2 = pd.concat([scores_z[\"Midterm\"], scores[\"Final\"]], axis=1, keys=[\"midterm_normalized\", \"finals_original\"]).corr(method=\"pearson\").iloc[0,1]\n",
    "print(\"The Pearson’s correlation coefficient between midterm-normalized and finals-original is: \"+str(cor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tthe covariance between midterm-original and finals-original is: 78.2541941941942\n"
     ]
    }
   ],
   "source": [
    "cov = scores.cov().iloc[1,2]\n",
    "print(\"Tthe covariance between midterm-original and finals-original is: \"+str(cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "- The original data is given as string, so first we need to change the format to format.\n",
    "- `distance.minkowski()` and `distance.cosine()` are used to calculate the Minkowski distance and cosine distance. As we need the cosine similarity, we need to subsract the cosince distance derived from 1.\n",
    "- To calculate KL divergence, we need to first construct probability distribution and then use `scipy.special.rel_entr` function.\n",
    "\n",
    "\n",
    "### 3.(a) compute the Minkowski distance of the vectors for CML and CBL with regard to different `h` values:\n",
    "`h=1:`6152\\\n",
    "`h=2:`715.328\\\n",
    "`h=3:`170\n",
    "\n",
    "### 3.(b) Compute the cosine similarity between the feature vectors for CML and CBL\n",
    "0.841\n",
    "\n",
    "### 3.(c) Compute the Kullback-Leibler (KL) divergence between CML and CBL by constructing probability distributions for each library based on their feature vectors.\n",
    "0.207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.libraries.inventories.txt\", delimiter=\"\\t\",header=None)\n",
    "df = df.T\n",
    "new_header = df.iloc[0]\n",
    "df = df[1:]\n",
    "df.columns = new_header\n",
    "df[[\"CML\", \"CBL\"]] = df[[\"CML\", \"CBL\"]].apply(pd.to_numeric)\n",
    "df.head()\n",
    "cml = df[\"CML\"].to_numpy()\n",
    "cbl = df[\"CBL\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minkowski distance of the vectors for CML and CBL with regard to different h values are:\n",
      "6152.0\n",
      "715.3278968417211\n",
      "170.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "print(\"Minkowski distance of the vectors for CML and CBL with regard to different h values are:\")\n",
    "print(distance.minkowski(cml, cbl, 1))\n",
    "print(distance.minkowski(cml, cbl, 2))\n",
    "print(distance.minkowski(cml, cbl, float(\"inf\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the feature vectors for CML and CBL is: \n",
      "0.8414040256623079\n"
     ]
    }
   ],
   "source": [
    "print(\"The cosine similarity between the feature vectors for CML and CBL is: \")\n",
    "print(1-distance.cosine(cml, cbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KL divergence of the distributions for the libraries is:\n",
      "0.20708093733159474\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import rel_entr\n",
    "cml_dist=(df[\"CML\"]/sum(df[\"CML\"])).to_numpy()\n",
    "cbl_dist=(df[\"CBL\"]/sum(df[\"CBL\"])).to_numpy()\n",
    "print(\"The KL divergence of the distributions for the libraries is:\")\n",
    "print(sum(rel_entr(cml_dist, cbl_dist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "- First create a numpy array from the table\n",
    "- Given the symmetric binary variables, the distance can be derived from $\\frac{r+s}{q+s+r+t}$ \n",
    "- `stat.chi2_contingency()` gives me a quick way to calculate the $\\chi^2$ statistic\n",
    "- Also, `stat.chi2_contingency()` function will provide us the p-value, degree of freedom as well. By comparing the p-value with the $\\alpha$, we can check if we need to reject the null hypothesis\n",
    "\n",
    "### 4.(a) The distance between the binary attributes Buy Beer and Buy Diaper by assuming they are symmetric binary variables.\n",
    "0.0157\n",
    "\n",
    "### 4.(b) The Jaccard coefficient between Buy Beer and Buy Diaper.\n",
    "0.7317\n",
    "\n",
    "### 4.(c) The $\\chi^2$ statistic for the contingency table.\n",
    "2450.716\n",
    "\n",
    "### 4.(d) Consider a hypothesis test based on the $\\chi^2$ statistic where the null hypothesis is that Buy Beer and Buy Diaper are independent. Can you reject the null hypothesis at a significance level of α = 0.05? Explain your answer, and also mention the degrees of freedom used for the hypothesis test.\n",
    "We have to reject the null hypothesis as the p-value derived is smaller than 0.05.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the binary attributes Buy Beer and Buy Diaper is: 0.015691868758915834\n"
     ]
    }
   ],
   "source": [
    "cust = np.array([[150, 40], [15, 3300]])\n",
    "beer = cust[0][1]\n",
    "diaper = cust[1][0]\n",
    "print(\"The distance between the binary attributes Buy Beer and Buy Diaper is:\", (beer+diaper)/cust.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jaccard coefficient of between Buy Beer and Buy Diaper is: 0.7317073170731707\n"
     ]
    }
   ],
   "source": [
    "jac = cust[0][0] / (cust[0][0]+cust[0][1]+cust[1][0])\n",
    "print(\"The jaccard coefficient of between Buy Beer and Buy Diaper is:\", jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chi=square statistic for the contingeny table is: 2450.716326822006\n"
     ]
    }
   ],
   "source": [
    "print(\"The chi=square statistic for the contingeny table is:\", stats.chi2_contingency(cust)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have to reject the null hypothesis given the p-value as 0.0 and the degree of freedom of 1\n"
     ]
    }
   ],
   "source": [
    "if(stats.chi2_contingency(cust)[1]<0.05):\n",
    "    print(\"We have to reject the null hypothesis given the p-value as\", \n",
    "          stats.chi2_contingency(cust)[1], \n",
    "          \"and the degree of freedom of\", stats.chi2_contingency(cust)[2])\n",
    "else:\n",
    "    print(\"We are not able to reject the null hypothesis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
